{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function for Supervised Learning - \n",
    "\n",
    "    1. Regression  - L2-norm\n",
    "    2. Classification  - Cross-entropy\n",
    "    \n",
    "    Target - is desired value at which we are aiming\n",
    "    \n",
    "We want our output to be as close as possible to target. In cats vs dogs example, targets would be validated labels we assign.\n",
    "\n",
    "The Y values are the outputs of our model, the machine learning algorithm aims to find a function of X that outputs values as close to the targets as possible.\n",
    "\n",
    "Using this new notation, the last function evaluates the accuracy of the outputs regarding the targets.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output (Y = f(X))   <-   target T    <-   Accuracy    <-  Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l2 - norm\n",
    "\n",
    "Also called as squared loss. Method to calculate l2-norm is least squared method.\n",
    "\n",
    "L2 norm = Σi(yi -t)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-entropy\n",
    "\n",
    "= minus the sum of the targets times the natural log of the outputs.\n",
    "\n",
    "L(y,t) = -Σi ti ln(yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization Algorithm\n",
    "\n",
    "Gradient Descent - multivariate generalization of derivative concept. \n",
    "\n",
    "The actual optimization process happens when the optimization algorithm varies the models\n",
    "parameters until the loss function has been minimized in the context of the linear model.\n",
    "\n",
    "This implies varying W and B, OK, the simplest and the most fundamental optimization algorithm is\n",
    "the gradient descent.\n",
    "\n",
    "Let's first consider a non machine learning example to understand the logic behind the gradient descent.\n",
    "\n",
    "Here's a function F of X equal to five times X squared, plus three times X minus four.\n",
    "\n",
    "    f(x) = 5x**2+3x-4\n",
    "\n",
    "Our goal is to find the minimum of this function using the gradient descent methodology.\n",
    "The first step is to find the first derivative of the function.\n",
    "\n",
    "In our case it is ten times X plus three.\n",
    "\n",
    "    f'(x) = 10x+3\n",
    "    if xo = 4,\n",
    "    x1 = ?\n",
    "    xi+1 = xi - learning_rate * f'(xi)\n",
    "    => xi+1 = 4 - learning_rate * 43\n",
    "\n",
    "\n",
    "Using the update rule, we can find X2, x3 and so on.\n",
    "\n",
    "After conducting the update operation long enough, the values will eventually stop updating.\n",
    "That is the point at which we know we have reached the minimum of the function.\n",
    "This is because the first derivative of the function is zero when we have reached the GLOBAL minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-parameter gradient descent\n",
    "\n",
    "xw + b = y  -> model\n",
    "###### xiw+ b = yi -> ti\n",
    "\n",
    "L(y,t)      -> loss function\n",
    "\n",
    "C(y,t)      -> cost function\n",
    "\n",
    "E(y,t)      -> Error function\n",
    "\n",
    "Lets look at l2 norm loss\n",
    "\n",
    "###### loss: L(y,t) = L2 norm = (Σi(yi -t)**2)/2\n",
    "\n",
    "    Any function that holds the basic property of \n",
    "    higher for worse results\n",
    "    lower for better results\n",
    "    can be a loss function\n",
    "    \n",
    "##### Update Rule\n",
    "\n",
    "    xi+1 = xi - learning_rate * f'(xi)\n",
    "    \n",
    "    wi+1 = wi - learning_rate *deltaw L(y,t)\n",
    "    \n",
    "    bi+1 = wi - learning_rate *deltab L(y,t)\n",
    "    \n",
    "The first derivative at EXI becomes WSI, plus one equals WSI minus Eita Times the gradient of the loss\n",
    "function with respect to w I for the weights and \n",
    "\n",
    "B.I plus one equals B.I minus Eita times the gradient of the loss function With respect to be for the bias's it is basically the same, but for a matrix W any vector B instead of a number X.\n",
    "\n",
    "\n",
    "    To minimize loss function means -> loss: L(y,t) = L2 norm = (Σi(yi -t)**2)/2\n",
    "\n",
    "    To optimize :\n",
    "\n",
    "    wi+1 = wi - learning_rate *deltaw L(y,t)\n",
    "    \n",
    "    bi+1 = wi - learning_rate *deltab L(y,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"sales_data_training.csv\")\n",
    "\n",
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"sales_data_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "scaled_training = scaler.fit_transform(training_data_df)\n",
    "scaled_testing = scaler.transform(test_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: total_earnings values were scaled by multiplying by 0.0000036968 and adding -0.115913\n"
     ]
    }
   ],
   "source": [
    "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
    "print(\"Note: total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], scaler.min_[8]))\n",
    "\n",
    "# Create new pandas DataFrame objects from the scaled data\n",
    "scaled_training_df = pd.DataFrame(scaled_training, columns=training_data_df.columns.values)\n",
    "scaled_testing_df = pd.DataFrame(scaled_testing, columns=test_data_df.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save scaled data dataframes to new CSV files\n",
    "scaled_training_df.to_csv(\"sales_data_training_scaled.csv\", index=False)\n",
    "scaled_testing_df.to_csv(\"sales_data_testing_scaled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=9, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 - 0s - loss: 0.0245\n",
      "Epoch 2/50\n",
      "32/32 - 0s - loss: 0.0029\n",
      "Epoch 3/50\n",
      "32/32 - 0s - loss: 0.0011\n",
      "Epoch 4/50\n",
      "32/32 - 0s - loss: 5.4315e-04\n",
      "Epoch 5/50\n",
      "32/32 - 0s - loss: 3.3731e-04\n",
      "Epoch 6/50\n",
      "32/32 - 0s - loss: 2.3508e-04\n",
      "Epoch 7/50\n",
      "32/32 - 0s - loss: 2.0049e-04\n",
      "Epoch 8/50\n",
      "32/32 - 0s - loss: 1.3711e-04\n",
      "Epoch 9/50\n",
      "32/32 - 0s - loss: 1.1317e-04\n",
      "Epoch 10/50\n",
      "32/32 - 0s - loss: 1.0248e-04\n",
      "Epoch 11/50\n",
      "32/32 - 0s - loss: 9.6386e-05\n",
      "Epoch 12/50\n",
      "32/32 - 0s - loss: 7.0687e-05\n",
      "Epoch 13/50\n",
      "32/32 - 0s - loss: 6.5732e-05\n",
      "Epoch 14/50\n",
      "32/32 - 0s - loss: 5.3585e-05\n",
      "Epoch 15/50\n",
      "32/32 - 0s - loss: 5.1114e-05\n",
      "Epoch 16/50\n",
      "32/32 - 0s - loss: 4.7881e-05\n",
      "Epoch 17/50\n",
      "32/32 - 0s - loss: 4.1606e-05\n",
      "Epoch 18/50\n",
      "32/32 - 0s - loss: 3.9282e-05\n",
      "Epoch 19/50\n",
      "32/32 - 0s - loss: 3.7770e-05\n",
      "Epoch 20/50\n",
      "32/32 - 0s - loss: 3.7655e-05\n",
      "Epoch 21/50\n",
      "32/32 - 0s - loss: 3.2275e-05\n",
      "Epoch 22/50\n",
      "32/32 - 0s - loss: 3.2085e-05\n",
      "Epoch 23/50\n",
      "32/32 - 0s - loss: 2.9304e-05\n",
      "Epoch 24/50\n",
      "32/32 - 0s - loss: 3.5047e-05\n",
      "Epoch 25/50\n",
      "32/32 - 0s - loss: 5.0714e-05\n",
      "Epoch 26/50\n",
      "32/32 - 0s - loss: 4.1857e-05\n",
      "Epoch 27/50\n",
      "32/32 - 0s - loss: 3.0099e-05\n",
      "Epoch 28/50\n",
      "32/32 - 0s - loss: 2.8317e-05\n",
      "Epoch 29/50\n",
      "32/32 - 0s - loss: 2.6566e-05\n",
      "Epoch 30/50\n",
      "32/32 - 0s - loss: 2.6127e-05\n",
      "Epoch 31/50\n",
      "32/32 - 0s - loss: 2.5335e-05\n",
      "Epoch 32/50\n",
      "32/32 - 0s - loss: 2.5200e-05\n",
      "Epoch 33/50\n",
      "32/32 - 0s - loss: 2.2371e-05\n",
      "Epoch 34/50\n",
      "32/32 - 0s - loss: 3.2018e-05\n",
      "Epoch 35/50\n",
      "32/32 - 0s - loss: 2.2866e-05\n",
      "Epoch 36/50\n",
      "32/32 - 0s - loss: 2.8339e-05\n",
      "Epoch 37/50\n",
      "32/32 - 0s - loss: 2.9523e-05\n",
      "Epoch 38/50\n",
      "32/32 - 0s - loss: 2.8741e-05\n",
      "Epoch 39/50\n",
      "32/32 - 0s - loss: 2.8423e-05\n",
      "Epoch 40/50\n",
      "32/32 - 0s - loss: 2.4174e-05\n",
      "Epoch 41/50\n",
      "32/32 - 0s - loss: 2.3452e-05\n",
      "Epoch 42/50\n",
      "32/32 - 0s - loss: 2.8945e-05\n",
      "Epoch 43/50\n",
      "32/32 - 0s - loss: 3.2376e-05\n",
      "Epoch 44/50\n",
      "32/32 - 0s - loss: 1.9786e-05\n",
      "Epoch 45/50\n",
      "32/32 - 0s - loss: 2.7550e-05\n",
      "Epoch 46/50\n",
      "32/32 - 0s - loss: 2.0360e-05\n",
      "Epoch 47/50\n",
      "32/32 - 0s - loss: 2.6998e-05\n",
      "Epoch 48/50\n",
      "32/32 - 0s - loss: 2.8350e-05\n",
      "Epoch 49/50\n",
      "32/32 - 0s - loss: 2.5524e-05\n",
      "Epoch 50/50\n",
      "32/32 - 0s - loss: 2.4033e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2086b3cd6d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2 #prints more detailed info\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) for the test data set is: 0.0001405855582561344\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the separate test data set\n",
    "test_data_df = pd.read_csv(\"sales_data_testing_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 415us/step - loss: 1.4059e-04\n",
      "The mean squared error (MSE) for the test data set is: 0.0001405855582561344\n"
     ]
    }
   ],
   "source": [
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 - 0s - loss: 1.4059e-04\n",
      "The mean squared error (MSE) for the test data set is: 0.0001405855582561344\n"
     ]
    }
   ],
   "source": [
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data we make to use to make a prediction\n",
    "X = pd.read_csv(\"proposed_new_product.csv\").values\n",
    "\n",
    "# Make a prediction with the neural network\n",
    "prediction = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just the first element of the first prediction (since that's the only have one)\n",
    "prediction = prediction[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings Prediction for Proposed Product - $264378.67422997503\n"
     ]
    }
   ],
   "source": [
    "# Re-scale the data from the 0-to-1 range back to dollars\n",
    "# These constants are from when the data was originally scaled down to the 0-to-1 range\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.0000036968\n",
    "\n",
    "print(\"Earnings Prediction for Proposed Product - ${}\".format(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings Prediction for Proposed Product - $264378.67422997503\n"
     ]
    }
   ],
   "source": [
    "model = load_model('trained_model.h5')\n",
    "\n",
    "X = pd.read_csv(\"proposed_new_product.csv\").values\n",
    "prediction = model.predict(X)\n",
    "\n",
    "# Grab just the first element of the first prediction (since we only have one)\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "# Re-scale the data from the 0-to-1 range back to dollars\n",
    "# These constants are from when the data was originally scaled down to the 0-to-1 range\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.0000036968\n",
    "\n",
    "print(\"Earnings Prediction for Proposed Product - ${}\".format(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
