{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOYMENT\n",
    "\n",
    "**Welcome to deployment section! In this section of the course, we will go through the entire deployment process, starting as if you had to create a servicable model from scratch, then deploy it for others to use, either through API or a web form.**\n",
    "\n",
    "# Data\n",
    "\n",
    "For this example we use the very common data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
    "\n",
    "From Wikipedia:\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gasp√© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"../DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of ways to one hot encode\n",
    "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1.2651 - accuracy: 0.6333 - val_loss: 1.1583 - val_accuracy: 0.7000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2590 - accuracy: 0.6167 - val_loss: 1.1547 - val_accuracy: 0.6667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2518 - accuracy: 0.6167 - val_loss: 1.1514 - val_accuracy: 0.7000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2454 - accuracy: 0.6250 - val_loss: 1.1481 - val_accuracy: 0.7000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2390 - accuracy: 0.6167 - val_loss: 1.1450 - val_accuracy: 0.6667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2326 - accuracy: 0.6167 - val_loss: 1.1421 - val_accuracy: 0.6667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2268 - accuracy: 0.6167 - val_loss: 1.1392 - val_accuracy: 0.6667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2209 - accuracy: 0.6167 - val_loss: 1.1366 - val_accuracy: 0.6667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2156 - accuracy: 0.6167 - val_loss: 1.1340 - val_accuracy: 0.6667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2102 - accuracy: 0.6167 - val_loss: 1.1316 - val_accuracy: 0.6667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2048 - accuracy: 0.6167 - val_loss: 1.1294 - val_accuracy: 0.6667\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.2000 - accuracy: 0.6167 - val_loss: 1.1273 - val_accuracy: 0.6667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1956 - accuracy: 0.6083 - val_loss: 1.1253 - val_accuracy: 0.6667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1908 - accuracy: 0.6000 - val_loss: 1.1235 - val_accuracy: 0.6333\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1862 - accuracy: 0.5917 - val_loss: 1.1218 - val_accuracy: 0.6333\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1828 - accuracy: 0.5917 - val_loss: 1.1202 - val_accuracy: 0.6333\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1785 - accuracy: 0.5833 - val_loss: 1.1188 - val_accuracy: 0.6000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1747 - accuracy: 0.5750 - val_loss: 1.1174 - val_accuracy: 0.6000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1711 - accuracy: 0.5750 - val_loss: 1.1161 - val_accuracy: 0.6000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1681 - accuracy: 0.5750 - val_loss: 1.1149 - val_accuracy: 0.6000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1648 - accuracy: 0.5750 - val_loss: 1.1139 - val_accuracy: 0.6000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1618 - accuracy: 0.5750 - val_loss: 1.1128 - val_accuracy: 0.6000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1587 - accuracy: 0.5667 - val_loss: 1.1119 - val_accuracy: 0.6000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1560 - accuracy: 0.5417 - val_loss: 1.1110 - val_accuracy: 0.6000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1532 - accuracy: 0.5333 - val_loss: 1.1102 - val_accuracy: 0.5333\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1506 - accuracy: 0.5167 - val_loss: 1.1093 - val_accuracy: 0.5667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.1484 - accuracy: 0.5167 - val_loss: 1.1086 - val_accuracy: 0.5000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1459 - accuracy: 0.5083 - val_loss: 1.1079 - val_accuracy: 0.4667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1437 - accuracy: 0.5000 - val_loss: 1.1073 - val_accuracy: 0.4333\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1417 - accuracy: 0.4833 - val_loss: 1.1067 - val_accuracy: 0.4000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1393 - accuracy: 0.4500 - val_loss: 1.1061 - val_accuracy: 0.4000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1375 - accuracy: 0.4083 - val_loss: 1.1056 - val_accuracy: 0.4000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1356 - accuracy: 0.3917 - val_loss: 1.1050 - val_accuracy: 0.4000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1337 - accuracy: 0.3667 - val_loss: 1.1045 - val_accuracy: 0.3667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1322 - accuracy: 0.3500 - val_loss: 1.1041 - val_accuracy: 0.3667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1302 - accuracy: 0.3333 - val_loss: 1.1036 - val_accuracy: 0.3333\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1287 - accuracy: 0.3083 - val_loss: 1.1031 - val_accuracy: 0.3333\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1271 - accuracy: 0.2917 - val_loss: 1.1026 - val_accuracy: 0.3333\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1257 - accuracy: 0.2750 - val_loss: 1.1023 - val_accuracy: 0.3333\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1241 - accuracy: 0.2417 - val_loss: 1.1019 - val_accuracy: 0.3333\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1226 - accuracy: 0.2333 - val_loss: 1.1014 - val_accuracy: 0.3333\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1212 - accuracy: 0.2000 - val_loss: 1.1010 - val_accuracy: 0.3000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1200 - accuracy: 0.1917 - val_loss: 1.1006 - val_accuracy: 0.3000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1185 - accuracy: 0.1917 - val_loss: 1.1002 - val_accuracy: 0.2667\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1173 - accuracy: 0.1750 - val_loss: 1.0998 - val_accuracy: 0.2667\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1160 - accuracy: 0.1583 - val_loss: 1.0993 - val_accuracy: 0.2667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1148 - accuracy: 0.1500 - val_loss: 1.0989 - val_accuracy: 0.2333\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1135 - accuracy: 0.1500 - val_loss: 1.0985 - val_accuracy: 0.2000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1124 - accuracy: 0.1250 - val_loss: 1.0981 - val_accuracy: 0.1667\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1113 - accuracy: 0.1167 - val_loss: 1.0977 - val_accuracy: 0.1667\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1101 - accuracy: 0.1167 - val_loss: 1.0972 - val_accuracy: 0.1667\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1090 - accuracy: 0.1167 - val_loss: 1.0967 - val_accuracy: 0.1333\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1079 - accuracy: 0.1083 - val_loss: 1.0963 - val_accuracy: 0.1333\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1069 - accuracy: 0.1000 - val_loss: 1.0959 - val_accuracy: 0.1333\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1057 - accuracy: 0.0917 - val_loss: 1.0953 - val_accuracy: 0.1333\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1047 - accuracy: 0.0917 - val_loss: 1.0948 - val_accuracy: 0.1000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1036 - accuracy: 0.0750 - val_loss: 1.0943 - val_accuracy: 0.1000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1026 - accuracy: 0.0750 - val_loss: 1.0937 - val_accuracy: 0.1000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1017 - accuracy: 0.0750 - val_loss: 1.0933 - val_accuracy: 0.1000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1005 - accuracy: 0.0583 - val_loss: 1.0926 - val_accuracy: 0.1000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0995 - accuracy: 0.0583 - val_loss: 1.0920 - val_accuracy: 0.1000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0986 - accuracy: 0.0667 - val_loss: 1.0915 - val_accuracy: 0.1000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0975 - accuracy: 0.0667 - val_loss: 1.0909 - val_accuracy: 0.1333\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0965 - accuracy: 0.0667 - val_loss: 1.0903 - val_accuracy: 0.1333\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0955 - accuracy: 0.0667 - val_loss: 1.0896 - val_accuracy: 0.1333\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0945 - accuracy: 0.0583 - val_loss: 1.0890 - val_accuracy: 0.1333\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0934 - accuracy: 0.0583 - val_loss: 1.0883 - val_accuracy: 0.1333\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0925 - accuracy: 0.0500 - val_loss: 1.0877 - val_accuracy: 0.1667\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0914 - accuracy: 0.0583 - val_loss: 1.0869 - val_accuracy: 0.1667\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0904 - accuracy: 0.0667 - val_loss: 1.0861 - val_accuracy: 0.1667\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0894 - accuracy: 0.0750 - val_loss: 1.0853 - val_accuracy: 0.2000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0884 - accuracy: 0.0750 - val_loss: 1.0844 - val_accuracy: 0.2000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0873 - accuracy: 0.0750 - val_loss: 1.0836 - val_accuracy: 0.2000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0862 - accuracy: 0.0833 - val_loss: 1.0827 - val_accuracy: 0.2000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0852 - accuracy: 0.1000 - val_loss: 1.0817 - val_accuracy: 0.2000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0841 - accuracy: 0.1000 - val_loss: 1.0808 - val_accuracy: 0.2000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0830 - accuracy: 0.1000 - val_loss: 1.0800 - val_accuracy: 0.2000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0819 - accuracy: 0.1167 - val_loss: 1.0791 - val_accuracy: 0.2333\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0808 - accuracy: 0.1250 - val_loss: 1.0782 - val_accuracy: 0.2333\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0796 - accuracy: 0.1250 - val_loss: 1.0771 - val_accuracy: 0.2667\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0784 - accuracy: 0.1250 - val_loss: 1.0761 - val_accuracy: 0.2667\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0772 - accuracy: 0.1333 - val_loss: 1.0751 - val_accuracy: 0.3000\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0761 - accuracy: 0.1500 - val_loss: 1.0740 - val_accuracy: 0.3000\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0748 - accuracy: 0.1583 - val_loss: 1.0729 - val_accuracy: 0.3000\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0737 - accuracy: 0.1583 - val_loss: 1.0718 - val_accuracy: 0.2667\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0724 - accuracy: 0.1750 - val_loss: 1.0705 - val_accuracy: 0.2667\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0711 - accuracy: 0.1750 - val_loss: 1.0693 - val_accuracy: 0.2667\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0698 - accuracy: 0.1833 - val_loss: 1.0680 - val_accuracy: 0.2333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0685 - accuracy: 0.1917 - val_loss: 1.0667 - val_accuracy: 0.2333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0672 - accuracy: 0.2000 - val_loss: 1.0655 - val_accuracy: 0.2333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0657 - accuracy: 0.2333 - val_loss: 1.0642 - val_accuracy: 0.2333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0643 - accuracy: 0.2417 - val_loss: 1.0629 - val_accuracy: 0.2333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0629 - accuracy: 0.2667 - val_loss: 1.0614 - val_accuracy: 0.2333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0614 - accuracy: 0.2667 - val_loss: 1.0601 - val_accuracy: 0.2667\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0599 - accuracy: 0.2833 - val_loss: 1.0587 - val_accuracy: 0.2667\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0583 - accuracy: 0.2917 - val_loss: 1.0572 - val_accuracy: 0.2667\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0568 - accuracy: 0.2917 - val_loss: 1.0556 - val_accuracy: 0.2667\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0552 - accuracy: 0.3000 - val_loss: 1.0540 - val_accuracy: 0.2333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0536 - accuracy: 0.3000 - val_loss: 1.0524 - val_accuracy: 0.2667\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0519 - accuracy: 0.3250 - val_loss: 1.0508 - val_accuracy: 0.2667\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0502 - accuracy: 0.3250 - val_loss: 1.0492 - val_accuracy: 0.2667\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0485 - accuracy: 0.3333 - val_loss: 1.0476 - val_accuracy: 0.2667\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0468 - accuracy: 0.3333 - val_loss: 1.0460 - val_accuracy: 0.2667\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0450 - accuracy: 0.3417 - val_loss: 1.0442 - val_accuracy: 0.2667\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0432 - accuracy: 0.3417 - val_loss: 1.0424 - val_accuracy: 0.2667\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.3500 - val_loss: 1.0407 - val_accuracy: 0.2667\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0395 - accuracy: 0.3667 - val_loss: 1.0387 - val_accuracy: 0.2667\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0377 - accuracy: 0.3917 - val_loss: 1.0369 - val_accuracy: 0.2667\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0357 - accuracy: 0.4000 - val_loss: 1.0350 - val_accuracy: 0.2667\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0336 - accuracy: 0.4083 - val_loss: 1.0331 - val_accuracy: 0.2667\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0316 - accuracy: 0.4167 - val_loss: 1.0310 - val_accuracy: 0.3000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0296 - accuracy: 0.4250 - val_loss: 1.0289 - val_accuracy: 0.3000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0275 - accuracy: 0.4083 - val_loss: 1.0269 - val_accuracy: 0.3000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0255 - accuracy: 0.4000 - val_loss: 1.0247 - val_accuracy: 0.3333\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0233 - accuracy: 0.4000 - val_loss: 1.0227 - val_accuracy: 0.3333\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0211 - accuracy: 0.4000 - val_loss: 1.0206 - val_accuracy: 0.3333\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0189 - accuracy: 0.4000 - val_loss: 1.0185 - val_accuracy: 0.3333\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0167 - accuracy: 0.4000 - val_loss: 1.0164 - val_accuracy: 0.3333\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0144 - accuracy: 0.4000 - val_loss: 1.0143 - val_accuracy: 0.3333\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0122 - accuracy: 0.4000 - val_loss: 1.0121 - val_accuracy: 0.3000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0097 - accuracy: 0.4000 - val_loss: 1.0099 - val_accuracy: 0.3000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0074 - accuracy: 0.4000 - val_loss: 1.0077 - val_accuracy: 0.3000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0051 - accuracy: 0.3917 - val_loss: 1.0054 - val_accuracy: 0.3000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0026 - accuracy: 0.3917 - val_loss: 1.0030 - val_accuracy: 0.3000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0001 - accuracy: 0.3917 - val_loss: 1.0007 - val_accuracy: 0.3000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9977 - accuracy: 0.3917 - val_loss: 0.9984 - val_accuracy: 0.3000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9952 - accuracy: 0.3833 - val_loss: 0.9960 - val_accuracy: 0.3000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9926 - accuracy: 0.3833 - val_loss: 0.9936 - val_accuracy: 0.3000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9901 - accuracy: 0.3833 - val_loss: 0.9912 - val_accuracy: 0.3000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9876 - accuracy: 0.3833 - val_loss: 0.9889 - val_accuracy: 0.3000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9848 - accuracy: 0.3833 - val_loss: 0.9863 - val_accuracy: 0.3000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9821 - accuracy: 0.3833 - val_loss: 0.9837 - val_accuracy: 0.3000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9795 - accuracy: 0.3833 - val_loss: 0.9811 - val_accuracy: 0.3000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9766 - accuracy: 0.3750 - val_loss: 0.9784 - val_accuracy: 0.3000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9738 - accuracy: 0.3750 - val_loss: 0.9756 - val_accuracy: 0.3000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9711 - accuracy: 0.3750 - val_loss: 0.9730 - val_accuracy: 0.3000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9679 - accuracy: 0.3750 - val_loss: 0.9702 - val_accuracy: 0.3000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9649 - accuracy: 0.3750 - val_loss: 0.9674 - val_accuracy: 0.3000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9619 - accuracy: 0.3833 - val_loss: 0.9644 - val_accuracy: 0.3000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9585 - accuracy: 0.3833 - val_loss: 0.9615 - val_accuracy: 0.3000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9553 - accuracy: 0.3833 - val_loss: 0.9584 - val_accuracy: 0.3000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9519 - accuracy: 0.3833 - val_loss: 0.9552 - val_accuracy: 0.3000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9484 - accuracy: 0.3833 - val_loss: 0.9518 - val_accuracy: 0.3000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9447 - accuracy: 0.3833 - val_loss: 0.9484 - val_accuracy: 0.3000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9410 - accuracy: 0.3833 - val_loss: 0.9447 - val_accuracy: 0.3000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9371 - accuracy: 0.3750 - val_loss: 0.9409 - val_accuracy: 0.3000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9330 - accuracy: 0.3750 - val_loss: 0.9371 - val_accuracy: 0.3000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9288 - accuracy: 0.3833 - val_loss: 0.9331 - val_accuracy: 0.3000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9246 - accuracy: 0.3750 - val_loss: 0.9288 - val_accuracy: 0.3000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9199 - accuracy: 0.3750 - val_loss: 0.9245 - val_accuracy: 0.3000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9153 - accuracy: 0.3750 - val_loss: 0.9198 - val_accuracy: 0.3000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9104 - accuracy: 0.3833 - val_loss: 0.9151 - val_accuracy: 0.3333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9057 - accuracy: 0.3833 - val_loss: 0.9102 - val_accuracy: 0.3333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.9007 - accuracy: 0.3833 - val_loss: 0.9056 - val_accuracy: 0.3333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8956 - accuracy: 0.3833 - val_loss: 0.9009 - val_accuracy: 0.3667\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8910 - accuracy: 0.3833 - val_loss: 0.8964 - val_accuracy: 0.3667\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8861 - accuracy: 0.3833 - val_loss: 0.8918 - val_accuracy: 0.3667\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8812 - accuracy: 0.3833 - val_loss: 0.8871 - val_accuracy: 0.3667\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8762 - accuracy: 0.3833 - val_loss: 0.8824 - val_accuracy: 0.3667\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8710 - accuracy: 0.3917 - val_loss: 0.8778 - val_accuracy: 0.3667\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8664 - accuracy: 0.3917 - val_loss: 0.8730 - val_accuracy: 0.3667\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8612 - accuracy: 0.3917 - val_loss: 0.8683 - val_accuracy: 0.3667\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8563 - accuracy: 0.3917 - val_loss: 0.8636 - val_accuracy: 0.3667\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8512 - accuracy: 0.3917 - val_loss: 0.8589 - val_accuracy: 0.3667\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8463 - accuracy: 0.4083 - val_loss: 0.8542 - val_accuracy: 0.3667\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.8415 - accuracy: 0.4083 - val_loss: 0.8496 - val_accuracy: 0.3667\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8363 - accuracy: 0.4083 - val_loss: 0.8451 - val_accuracy: 0.3667\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.4083 - val_loss: 0.8405 - val_accuracy: 0.3667\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8266 - accuracy: 0.4083 - val_loss: 0.8362 - val_accuracy: 0.3667\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8217 - accuracy: 0.4000 - val_loss: 0.8317 - val_accuracy: 0.3667\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8170 - accuracy: 0.4083 - val_loss: 0.8271 - val_accuracy: 0.3667\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8122 - accuracy: 0.4167 - val_loss: 0.8228 - val_accuracy: 0.3667\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8075 - accuracy: 0.4167 - val_loss: 0.8184 - val_accuracy: 0.4000\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8027 - accuracy: 0.4250 - val_loss: 0.8139 - val_accuracy: 0.4000\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7980 - accuracy: 0.4250 - val_loss: 0.8097 - val_accuracy: 0.4000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7933 - accuracy: 0.4167 - val_loss: 0.8055 - val_accuracy: 0.4000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7888 - accuracy: 0.4167 - val_loss: 0.8013 - val_accuracy: 0.4000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7842 - accuracy: 0.4167 - val_loss: 0.7972 - val_accuracy: 0.4000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7798 - accuracy: 0.4167 - val_loss: 0.7931 - val_accuracy: 0.4000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7754 - accuracy: 0.4167 - val_loss: 0.7890 - val_accuracy: 0.4000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7710 - accuracy: 0.4167 - val_loss: 0.7850 - val_accuracy: 0.4000\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7666 - accuracy: 0.4167 - val_loss: 0.7810 - val_accuracy: 0.4000\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7623 - accuracy: 0.4167 - val_loss: 0.7771 - val_accuracy: 0.4000\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7580 - accuracy: 0.4000 - val_loss: 0.7733 - val_accuracy: 0.3667\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7537 - accuracy: 0.3917 - val_loss: 0.7696 - val_accuracy: 0.3333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7496 - accuracy: 0.3917 - val_loss: 0.7658 - val_accuracy: 0.3333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7455 - accuracy: 0.3833 - val_loss: 0.7622 - val_accuracy: 0.3333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7414 - accuracy: 0.3833 - val_loss: 0.7586 - val_accuracy: 0.3667\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.3750 - val_loss: 0.7549 - val_accuracy: 0.3667\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7334 - accuracy: 0.3750 - val_loss: 0.7515 - val_accuracy: 0.3667\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.3833 - val_loss: 0.7478 - val_accuracy: 0.3667\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7256 - accuracy: 0.3833 - val_loss: 0.7443 - val_accuracy: 0.3667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.3750 - val_loss: 0.7409 - val_accuracy: 0.3667\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7179 - accuracy: 0.3750 - val_loss: 0.7375 - val_accuracy: 0.3667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7142 - accuracy: 0.3667 - val_loss: 0.7342 - val_accuracy: 0.3667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7105 - accuracy: 0.3667 - val_loss: 0.7309 - val_accuracy: 0.3667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7068 - accuracy: 0.3750 - val_loss: 0.7276 - val_accuracy: 0.3667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7032 - accuracy: 0.3750 - val_loss: 0.7244 - val_accuracy: 0.3667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.3667 - val_loss: 0.7213 - val_accuracy: 0.4333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.3917 - val_loss: 0.7182 - val_accuracy: 0.4667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.4000 - val_loss: 0.7150 - val_accuracy: 0.5000\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.4083 - val_loss: 0.7119 - val_accuracy: 0.5000\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.4500 - val_loss: 0.7089 - val_accuracy: 0.5000\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6824 - accuracy: 0.4667 - val_loss: 0.7060 - val_accuracy: 0.5000\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.4667 - val_loss: 0.7031 - val_accuracy: 0.5333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.4833 - val_loss: 0.7001 - val_accuracy: 0.5333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.5000 - val_loss: 0.6973 - val_accuracy: 0.5333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6692 - accuracy: 0.5333 - val_loss: 0.6945 - val_accuracy: 0.5333\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6660 - accuracy: 0.5500 - val_loss: 0.6917 - val_accuracy: 0.5667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6630 - accuracy: 0.5750 - val_loss: 0.6891 - val_accuracy: 0.6000\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6599 - accuracy: 0.6167 - val_loss: 0.6865 - val_accuracy: 0.6000\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6568 - accuracy: 0.6333 - val_loss: 0.6838 - val_accuracy: 0.6000\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6538 - accuracy: 0.6667 - val_loss: 0.6813 - val_accuracy: 0.6000\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6508 - accuracy: 0.6750 - val_loss: 0.6788 - val_accuracy: 0.6000\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.6833 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6450 - accuracy: 0.6833 - val_loss: 0.6739 - val_accuracy: 0.6000\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6420 - accuracy: 0.6833 - val_loss: 0.6715 - val_accuracy: 0.6000\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6833 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6364 - accuracy: 0.6833 - val_loss: 0.6667 - val_accuracy: 0.6000\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.6833 - val_loss: 0.6644 - val_accuracy: 0.6000\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6833 - val_loss: 0.6621 - val_accuracy: 0.6000\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.6833 - val_loss: 0.6599 - val_accuracy: 0.6000\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.6833 - val_loss: 0.6577 - val_accuracy: 0.6000\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.6833 - val_loss: 0.6555 - val_accuracy: 0.6000\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.6833 - val_loss: 0.6534 - val_accuracy: 0.6000\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.6833 - val_loss: 0.6511 - val_accuracy: 0.6000\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.6833 - val_loss: 0.6491 - val_accuracy: 0.6000\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6833 - val_loss: 0.6471 - val_accuracy: 0.6000\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6106 - accuracy: 0.6833 - val_loss: 0.6451 - val_accuracy: 0.6000\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.6833 - val_loss: 0.6432 - val_accuracy: 0.6000\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6059 - accuracy: 0.6833 - val_loss: 0.6412 - val_accuracy: 0.6000\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6037 - accuracy: 0.6833 - val_loss: 0.6394 - val_accuracy: 0.6000\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6013 - accuracy: 0.6833 - val_loss: 0.6375 - val_accuracy: 0.6000\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5990 - accuracy: 0.6833 - val_loss: 0.6356 - val_accuracy: 0.6000\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5968 - accuracy: 0.6833 - val_loss: 0.6338 - val_accuracy: 0.6000\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.6833 - val_loss: 0.6321 - val_accuracy: 0.6000\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.6833 - val_loss: 0.6301 - val_accuracy: 0.6000\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5904 - accuracy: 0.6833 - val_loss: 0.6285 - val_accuracy: 0.6000\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.6833 - val_loss: 0.6268 - val_accuracy: 0.6000\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5862 - accuracy: 0.6833 - val_loss: 0.6252 - val_accuracy: 0.6000\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.6833 - val_loss: 0.6237 - val_accuracy: 0.6000\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5821 - accuracy: 0.6833 - val_loss: 0.6221 - val_accuracy: 0.6000\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.6833 - val_loss: 0.6204 - val_accuracy: 0.6000\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5782 - accuracy: 0.6833 - val_loss: 0.6188 - val_accuracy: 0.6000\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5763 - accuracy: 0.6833 - val_loss: 0.6174 - val_accuracy: 0.6000\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5744 - accuracy: 0.6833 - val_loss: 0.6159 - val_accuracy: 0.6000\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5727 - accuracy: 0.6833 - val_loss: 0.6145 - val_accuracy: 0.6000\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.5708 - accuracy: 0.6833 - val_loss: 0.6131 - val_accuracy: 0.6000\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5691 - accuracy: 0.6833 - val_loss: 0.6116 - val_accuracy: 0.6000\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5673 - accuracy: 0.6833 - val_loss: 0.6102 - val_accuracy: 0.6000\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.6833 - val_loss: 0.6086 - val_accuracy: 0.6000\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.6833 - val_loss: 0.6070 - val_accuracy: 0.6000\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.6833 - val_loss: 0.6057 - val_accuracy: 0.6000\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.6833 - val_loss: 0.6045 - val_accuracy: 0.6000\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.6833 - val_loss: 0.6030 - val_accuracy: 0.6000\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.6833 - val_loss: 0.6016 - val_accuracy: 0.6000\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.6833 - val_loss: 0.6003 - val_accuracy: 0.6000\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.6833 - val_loss: 0.5990 - val_accuracy: 0.6000\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.6833 - val_loss: 0.5978 - val_accuracy: 0.6000\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5512 - accuracy: 0.6833 - val_loss: 0.5965 - val_accuracy: 0.6000\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.6833 - val_loss: 0.5953 - val_accuracy: 0.6000\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.6833 - val_loss: 0.5940 - val_accuracy: 0.6000\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5469 - accuracy: 0.6833 - val_loss: 0.5927 - val_accuracy: 0.6000\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5455 - accuracy: 0.6833 - val_loss: 0.5914 - val_accuracy: 0.6000\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5441 - accuracy: 0.6833 - val_loss: 0.5902 - val_accuracy: 0.6000\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.6833 - val_loss: 0.5889 - val_accuracy: 0.6000\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5414 - accuracy: 0.6833 - val_loss: 0.5877 - val_accuracy: 0.6000\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5401 - accuracy: 0.6833 - val_loss: 0.5866 - val_accuracy: 0.6000\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.6833 - val_loss: 0.5854 - val_accuracy: 0.6000\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5375 - accuracy: 0.6833 - val_loss: 0.5842 - val_accuracy: 0.6000\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.6833 - val_loss: 0.5832 - val_accuracy: 0.6000\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.6833 - val_loss: 0.5819 - val_accuracy: 0.6000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5338 - accuracy: 0.6833 - val_loss: 0.5807 - val_accuracy: 0.6000\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.6833 - val_loss: 0.5797 - val_accuracy: 0.6000\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.6833 - val_loss: 0.5786 - val_accuracy: 0.6000\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.6833 - val_loss: 0.5774 - val_accuracy: 0.6000\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.6833 - val_loss: 0.5764 - val_accuracy: 0.6000\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.6833 - val_loss: 0.5754 - val_accuracy: 0.6000\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.6833 - val_loss: 0.5747 - val_accuracy: 0.6000\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.6833 - val_loss: 0.5738 - val_accuracy: 0.6000\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.6833 - val_loss: 0.5728 - val_accuracy: 0.6000\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5234 - accuracy: 0.6833 - val_loss: 0.5718 - val_accuracy: 0.6000\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5224 - accuracy: 0.6833 - val_loss: 0.5708 - val_accuracy: 0.6000\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5213 - accuracy: 0.6833 - val_loss: 0.5699 - val_accuracy: 0.6000\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5203 - accuracy: 0.6833 - val_loss: 0.5689 - val_accuracy: 0.6000\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5638 - accuracy: 0.59 - 0s 7ms/step - loss: 0.5193 - accuracy: 0.6833 - val_loss: 0.5678 - val_accuracy: 0.6000\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.6833 - val_loss: 0.5668 - val_accuracy: 0.6000\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5172 - accuracy: 0.6833 - val_loss: 0.5659 - val_accuracy: 0.6000\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.6833 - val_loss: 0.5651 - val_accuracy: 0.6000\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.6833 - val_loss: 0.5642 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.6833 - val_loss: 0.5633 - val_accuracy: 0.6000\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5133 - accuracy: 0.6833 - val_loss: 0.5623 - val_accuracy: 0.6000\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.6833 - val_loss: 0.5613 - val_accuracy: 0.6000\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.6833 - val_loss: 0.5604 - val_accuracy: 0.6000\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.6833 - val_loss: 0.5594 - val_accuracy: 0.6000\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.6833 - val_loss: 0.5586 - val_accuracy: 0.6000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.6833 - val_loss: 0.5576 - val_accuracy: 0.6000\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.6833 - val_loss: 0.5567 - val_accuracy: 0.6000\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.6833 - val_loss: 0.5559 - val_accuracy: 0.6000\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.6833 - val_loss: 0.5551 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170d2bee5e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.265147</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.158327</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.259041</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1.154703</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.251809</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1.151352</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.245366</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.148135</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.238999</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1.145048</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.509690</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.558575</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.508786</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.557608</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.507885</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.556743</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.507027</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.555866</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.506212</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.555088</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.265147  0.633333  1.158327      0.700000\n",
       "1    1.259041  0.616667  1.154703      0.666667\n",
       "2    1.251809  0.616667  1.151352      0.700000\n",
       "3    1.245366  0.625000  1.148135      0.700000\n",
       "4    1.238999  0.616667  1.145048      0.666667\n",
       "..        ...       ...       ...           ...\n",
       "295  0.509690  0.683333  0.558575      0.600000\n",
       "296  0.508786  0.683333  0.557608      0.600000\n",
       "297  0.507885  0.683333  0.556743      0.600000\n",
       "298  0.507027  0.683333  0.555866      0.600000\n",
       "299  0.506212  0.683333  0.555088      0.600000\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5550878643989563, 0.6000000238418579]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0795 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0753 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0714 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0676 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0638 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0598 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0560 - accuracy: 0.3533\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0522 - accuracy: 0.3800\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0484 - accuracy: 0.4000\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0446 - accuracy: 0.4467\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0409 - accuracy: 0.5133\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0372 - accuracy: 0.5667\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0336 - accuracy: 0.5933\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0303 - accuracy: 0.6333\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0271 - accuracy: 0.6467\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0240 - accuracy: 0.6533\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0210 - accuracy: 0.6600\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0181 - accuracy: 0.6600\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0153 - accuracy: 0.6600\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0126 - accuracy: 0.6600\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 1.0100 - accuracy: 0.6600\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0074 - accuracy: 0.6600\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0051 - accuracy: 0.6600\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0023 - accuracy: 0.6600\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9999 - accuracy: 0.6600\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9974 - accuracy: 0.6600\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9950 - accuracy: 0.6600\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9926 - accuracy: 0.6600\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9900 - accuracy: 0.6667\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.9876 - accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9850 - accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9825 - accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9800 - accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9775 - accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9748 - accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9698 - accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9671 - accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9645 - accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9620 - accuracy: 0.6667\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9593 - accuracy: 0.6667\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.6667\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9540 - accuracy: 0.6667\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9515 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9488 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9433 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9379 - accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9352 - accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9326 - accuracy: 0.6600\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9298 - accuracy: 0.6600\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9271 - accuracy: 0.6533\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9243 - accuracy: 0.6533\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9215 - accuracy: 0.6467\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9188 - accuracy: 0.6467\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9161 - accuracy: 0.6400\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9132 - accuracy: 0.6333\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9105 - accuracy: 0.6333\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9077 - accuracy: 0.6267\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.9049 - accuracy: 0.6067\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9021 - accuracy: 0.5733\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8993 - accuracy: 0.5600\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8965 - accuracy: 0.5200\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8937 - accuracy: 0.4733\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8910 - accuracy: 0.4333\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8881 - accuracy: 0.4067\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.8855 - accuracy: 0.3933\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8826 - accuracy: 0.3800\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8799 - accuracy: 0.3933\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8771 - accuracy: 0.4133\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 571us/step - loss: 0.8743 - accuracy: 0.4733\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8717 - accuracy: 0.5467\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8688 - accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8661 - accuracy: 0.6267\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8633 - accuracy: 0.6400\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8608 - accuracy: 0.6600\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8579 - accuracy: 0.6667\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8552 - accuracy: 0.6667\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8526 - accuracy: 0.6667\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8498 - accuracy: 0.6667\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.8471 - accuracy: 0.6667\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 499us/step - loss: 0.8444 - accuracy: 0.6667\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8418 - accuracy: 0.6667\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8391 - accuracy: 0.6667\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8365 - accuracy: 0.6667\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8339 - accuracy: 0.6667\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.8312 - accuracy: 0.6667\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.8285 - accuracy: 0.6667\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8259 - accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8234 - accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8207 - accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8182 - accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8155 - accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8130 - accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8104 - accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8079 - accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8053 - accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8029 - accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.8005 - accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7979 - accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7954 - accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7930 - accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7906 - accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7882 - accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7858 - accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7833 - accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7809 - accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7786 - accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7764 - accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7739 - accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7715 - accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7693 - accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7670 - accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7647 - accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7625 - accuracy: 0.6667\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7602 - accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7580 - accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7558 - accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7536 - accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7513 - accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7491 - accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7470 - accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7446 - accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7421 - accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7390 - accuracy: 0.6733\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7356 - accuracy: 0.6733\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.6800\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7289 - accuracy: 0.7000\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7261 - accuracy: 0.7133\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7223 - accuracy: 0.7333\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7193 - accuracy: 0.7733\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7164 - accuracy: 0.8067\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7132 - accuracy: 0.8000\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7102 - accuracy: 0.7867\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.7070 - accuracy: 0.7733\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7041 - accuracy: 0.7733\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7011 - accuracy: 0.7800\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6985 - accuracy: 0.7933\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.8067\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6925 - accuracy: 0.7933\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6897 - accuracy: 0.7933\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.7933\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6844 - accuracy: 0.8067\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6817 - accuracy: 0.8133\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6790 - accuracy: 0.8067\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6764 - accuracy: 0.8000\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6737 - accuracy: 0.8067\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.8067\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.6683 - accuracy: 0.8133\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6657 - accuracy: 0.8200\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6630 - accuracy: 0.8200\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6604 - accuracy: 0.8133\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.6577 - accuracy: 0.8067\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6549 - accuracy: 0.8067\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.6521 - accuracy: 0.8133\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6494 - accuracy: 0.8200\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6467 - accuracy: 0.8267\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 628us/step - loss: 0.6439 - accuracy: 0.8267\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6412 - accuracy: 0.8267\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6385 - accuracy: 0.8267\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6356 - accuracy: 0.8200\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6329 - accuracy: 0.8200\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 749us/step - loss: 0.6301 - accuracy: 0.8200\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6273 - accuracy: 0.8267\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6247 - accuracy: 0.8200\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6217 - accuracy: 0.8267\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6189 - accuracy: 0.8333\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6161 - accuracy: 0.8400\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6134 - accuracy: 0.8333\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6106 - accuracy: 0.8333\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6077 - accuracy: 0.8467\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6051 - accuracy: 0.8467\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.6029 - accuracy: 0.8400\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5995 - accuracy: 0.8400\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.5970 - accuracy: 0.8467\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.8467\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5914 - accuracy: 0.8467\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5890 - accuracy: 0.8467\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5861 - accuracy: 0.8533\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5833 - accuracy: 0.8533\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5807 - accuracy: 0.8533\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5780 - accuracy: 0.8533\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5754 - accuracy: 0.8533\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5728 - accuracy: 0.8533\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.8533\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5676 - accuracy: 0.8533\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5650 - accuracy: 0.8533\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5628 - accuracy: 0.8600\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.8600\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.8600\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5549 - accuracy: 0.8600\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.8600\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5498 - accuracy: 0.8600\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5474 - accuracy: 0.8600\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5449 - accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5424 - accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5401 - accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5377 - accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5352 - accuracy: 0.8600\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.5328 - accuracy: 0.8600\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5305 - accuracy: 0.8667\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5283 - accuracy: 0.8800\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5259 - accuracy: 0.8800\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5235 - accuracy: 0.8800\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5214 - accuracy: 0.8800\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5189 - accuracy: 0.8800\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5169 - accuracy: 0.8800\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.5146 - accuracy: 0.8733\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5123 - accuracy: 0.8733\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5100 - accuracy: 0.8733\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.5078 - accuracy: 0.8800\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.5056 - accuracy: 0.8800\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5036 - accuracy: 0.8800\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5014 - accuracy: 0.8800\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4992 - accuracy: 0.8800\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4971 - accuracy: 0.8800\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4949 - accuracy: 0.8800\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4929 - accuracy: 0.8800\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4908 - accuracy: 0.8800\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4887 - accuracy: 0.8800\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4867 - accuracy: 0.8800\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4848 - accuracy: 0.8800\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4827 - accuracy: 0.8800\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4808 - accuracy: 0.8800\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4788 - accuracy: 0.8800\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4768 - accuracy: 0.8800\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4748 - accuracy: 0.8800\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.4730 - accuracy: 0.8800\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4710 - accuracy: 0.8800\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4691 - accuracy: 0.8800\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4672 - accuracy: 0.8800\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4653 - accuracy: 0.8800\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 498us/step - loss: 0.4635 - accuracy: 0.8800\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4616 - accuracy: 0.8800\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4598 - accuracy: 0.8867\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4582 - accuracy: 0.8867\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4562 - accuracy: 0.8867\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4544 - accuracy: 0.8867\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4526 - accuracy: 0.8933\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4509 - accuracy: 0.8933\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.4491 - accuracy: 0.8933\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4473 - accuracy: 0.8933\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4456 - accuracy: 0.8933\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 499us/step - loss: 0.4438 - accuracy: 0.9000\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4421 - accuracy: 0.9000\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4404 - accuracy: 0.9000\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4388 - accuracy: 0.9000\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4370 - accuracy: 0.9000\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4354 - accuracy: 0.9133\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4338 - accuracy: 0.9067\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4321 - accuracy: 0.9133\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.9067\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.9067\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4273 - accuracy: 0.9133\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.9133\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4244 - accuracy: 0.9133\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.9000\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4210 - accuracy: 0.9067\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.9133\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4179 - accuracy: 0.9133\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.9133\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4148 - accuracy: 0.9133\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.9133\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4119 - accuracy: 0.9133\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.9133\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4089 - accuracy: 0.9133\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.9133\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4062 - accuracy: 0.9000\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4047 - accuracy: 0.9067\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4031 - accuracy: 0.9133\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4016 - accuracy: 0.9067\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.9133\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3988 - accuracy: 0.9133\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3973 - accuracy: 0.9133\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3960 - accuracy: 0.9133\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3946 - accuracy: 0.9133\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3933 - accuracy: 0.9133\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3920 - accuracy: 0.9133\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3906 - accuracy: 0.9200\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3892 - accuracy: 0.9133\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3879 - accuracy: 0.9133\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3865 - accuracy: 0.9133\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3852 - accuracy: 0.9133\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3839 - accuracy: 0.9133\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3831 - accuracy: 0.9200\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3813 - accuracy: 0.9200\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3801 - accuracy: 0.9200\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3790 - accuracy: 0.9200\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3775 - accuracy: 0.9200\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3763 - accuracy: 0.9200\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3752 - accuracy: 0.9200\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3738 - accuracy: 0.9200\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3725 - accuracy: 0.9200\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3713 - accuracy: 0.9267\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3701 - accuracy: 0.9267\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3691 - accuracy: 0.9333\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3679 - accuracy: 0.9467\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3665 - accuracy: 0.9400\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 499us/step - loss: 0.3654 - accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x170dbf9bac0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict(flower)\n",
    "    class_ind = np.argmax(class_ind)\n",
    "    \n",
    "    return classes[class_ind]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict(flower)\n",
    "    class_ind = np.argmax(class_ind, axis=1)\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
